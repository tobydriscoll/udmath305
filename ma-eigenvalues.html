<!DOCTYPE html>
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2019-04-25T14:26:14-04:00    *-->
<!--*                                    *-->
<!--*   http://mathbook.pugetsound.edu   *-->
<!--*                                    *-->
<!--**************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Eigenvalues</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width,  initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<script src="https://sagecell.sagemath.org/static/jquery.min.js"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']],
    },
    TeX: {
        extensions: ["extpfeil.js", "autobold.js", "https://aimath.org/mathbook/mathjaxknowl.js", ],
        // scrolling to fragment identifiers is controlled by other Javascript
        positionToHash: false,
        equationNumbers: { autoNumber: "none", useLabelIds: true, },
        TagSide: "right",
        TagIndent: ".8em",
    },
    // HTML-CSS output Jax to be dropped for MathJax 3.0
    "HTML-CSS": {
        scale: 88,
        mtextFontInherit: true,
    },
    CommonHTML: {
        scale: 88,
        mtextFontInherit: true,
    },
});
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML-full"></script><script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script><script src="https://aimath.org/knowl.js"></script><script src="https://aimath.org/mathbook/js/lib/jquery.sticky.js"></script><script src="https://aimath.org/mathbook/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.1/pretext.js"></script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://aimath.org/mathbook/stylesheets/mathbook-3.css" rel="stylesheet" type="text/css">
<link href="https://aimath.org/mathbook/mathbook-add-on2.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="mathbook-delaware.css">
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div class="hidden-content" style="display:none">\(  \newcommand{\dd}[2]{\frac{d #1}{d #2}}
  \renewcommand{\Re}{\text{Re}}
  \renewcommand{\Im}{\text{Im}}
  \newcommand{\Span}[1]{\langle#1\rangle}
  \newcommand{\spr}[1]{^{(#1)}}
  \newcommand{\dd}[2]{\frac{d #1}{d #2}}
  \newcommand{\ddd}[2]{\frac{d^2 #1}{d #2^2}}
  \newcommand{\pp}[2]{\frac{\partial #1}{\partial #2}}
  \newcommand{\norm}[1]{\left\| #1 \right\|}
  \newcommand{\det}{\operatorname{det}}
  \newcommand{\bzero}{\boldsymbol{0}}
  \newcommand{\bu}{\mathbf{u}}
  \newcommand{\bA}{\mathbf{A}}
  \newcommand{\bB}{\mathbf{B}}
  \newcommand{\bC}{\mathbf{C}}
 \newcommand{\bD}{\mathbf{D}}
  \newcommand{\bI}{\mathbf{I}}
  \newcommand{\bV}{\mathbf{V}}
\newcommand{\bff}{\mathbf{f}}
  \newcommand{\bx}{\mathbf{x}}
  \newcommand{\by}{\mathbf{y}}
  \newcommand{\bb}{\mathbf{b}}
  \newcommand{\bu}{\mathbf{u}}
  \newcommand{\bv}{\mathbf{v}}
  \newcommand{\bw}{\mathbf{w}}
  \newcommand{\bc}{\mathbf{c}}
  \newcommand{\bz}{\mathbf{z}}
  \newcommand{\inprod}[2]{\langle #1, #2 \rangle}
  \newcommand{\twovec}[2]{\begin{bmatrix}#1\\#2\end{bmatrix}}
  \newcommand{\twodet}[4]{\begin{vmatrix}#1 \amp #2\\#3 \amp #4\end{vmatrix}}
  \newcommand{\twomat}[4]{\begin{bmatrix}#1 \amp #2\\#3 \amp #4\end{bmatrix}}
  \newcommand{\twodiag}[2]{\begin{bmatrix} #1 \amp 0 \\ 0 \amp #2 \end{bmatrix}}
  \newcommand{\fourdiag}[3]{\begin{bmatrix} #1 \amp  \amp \amp  \\                    \amp #2 \amp  \amp  \\  \amp \amp \ddots \amp \\  \amp  \amp  \amp #3 \end{bmatrix}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="notes.html"><span class="title">Notes for MATH 305</span></a></h1>
<p class="byline">Toby Driscoll</p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3"><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="ma-nullspace.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="matrix-algebra.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="ma-diagonalization.html" title="Next">Next</a></span></div>
<button class="sidebar-right-toggle-button button active">Annotations</button>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="ma-nullspace.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="matrix-algebra.html" title="Up">Up</a><a class="next-button button toolbar-item" href="ma-diagonalization.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><h2 class="link"><a href="index.html" data-scroll="index"><span class="title">Front Matter</span></a></h2>
<ul><li><a href="preface-1.html" data-scroll="preface-1">Preface</a></li></ul>
<h2 class="link"><a href="first-order-ode.html" data-scroll="first-order-ode"><span class="codenumber">1</span> <span class="title">First-order ODEs</span></a></h2>
<ul>
<li><a href="linearity.html" data-scroll="linearity">Introduction</a></li>
<li><a href="exponentials.html" data-scroll="exponentials">Exponentials</a></li>
<li><a href="first-linear-ode.html" data-scroll="first-linear-ode">Linear ODEs</a></li>
<li><a href="first-linear-const.html" data-scroll="first-linear-const">Linear, constant-coefficients</a></li>
<li><a href="complex-exp.html" data-scroll="complex-exp">Using complex numbers</a></li>
<li><a href="variable-coeffs.html" data-scroll="variable-coeffs">Linear, variable coefficient</a></li>
<li><a href="first-order-models.html" data-scroll="first-order-models">Modeling with first-order ODEs</a></li>
<li><a href="steady-states.html" data-scroll="steady-states">Steady states</a></li>
<li><a href="logistic-equation.html" data-scroll="logistic-equation">Logistic equation</a></li>
<li><a href="separable.html" data-scroll="separable">Separable equations</a></li>
<li><a href="laplace-solutions.html" data-scroll="laplace-solutions">Laplace transform methods</a></li>
</ul>
<h2 class="link"><a href="second-order-ode.html" data-scroll="second-order-ode"><span class="codenumber">2</span> <span class="title">Second-order ODEs</span></a></h2>
<ul>
<li><a href="so-simple-harmonic.html" data-scroll="so-simple-harmonic">Simple harmonic motion</a></li>
<li><a href="so-complex-exponentials.html" data-scroll="so-complex-exponentials">Complex exponentials</a></li>
<li><a href="so-constant-coefficients.html" data-scroll="so-constant-coefficients">Constant coefficients</a></li>
<li><a href="so-forced-oscillators.html" data-scroll="so-forced-oscillators">Exponentially forced oscillators</a></li>
<li><a href="so-higher-order.html" data-scroll="so-higher-order">Higher-order ODEs</a></li>
<li><a href="so-applications.html" data-scroll="so-applications">Applications of oscillators</a></li>
<li><a href="so-general-forcing.html" data-scroll="so-general-forcing">Other forcing functions</a></li>
<li><a href="so-laplace.html" data-scroll="so-laplace">Laplace transform methods</a></li>
<li><a href="so-laplace-repeated.html" data-scroll="so-laplace-repeated">Repeated and complex poles</a></li>
<li><a href="so-convolutions.html" data-scroll="so-convolutions">Convolutions</a></li>
</ul>
<h2 class="link"><a href="two-dimensional-systems.html" data-scroll="two-dimensional-systems"><span class="codenumber">3</span> <span class="title">2D systems</span></a></h2>
<ul>
<li><a href="twod-slope-fields.html" data-scroll="twod-slope-fields">Slope fields</a></li>
<li><a href="twod-fixed-points.html" data-scroll="twod-fixed-points">Linear 2D systems</a></li>
<li><a href="twod-linearization.html" data-scroll="twod-linearization">Linearization</a></li>
</ul>
<h2 class="link"><a href="matrix-algebra.html" data-scroll="matrix-algebra"><span class="codenumber">4</span> <span class="title">Matrix algebra</span></a></h2>
<ul>
<li><a href="ma-rows-columns.html" data-scroll="ma-rows-columns">Rows and columns</a></li>
<li><a href="ma-elimination.html" data-scroll="ma-elimination">Elimination for linear systems</a></li>
<li><a href="ma-multiplication.html" data-scroll="ma-multiplication">Multiplying matrices</a></li>
<li><a href="ma-inverses.html" data-scroll="ma-inverses">Matrix inverses</a></li>
<li><a href="ma-nullspace.html" data-scroll="ma-nullspace">Nullspaces</a></li>
<li><a href="ma-eigenvalues.html" data-scroll="ma-eigenvalues" class="active">Eigenvalues</a></li>
<li><a href="ma-diagonalization.html" data-scroll="ma-diagonalization">Diagonalization</a></li>
<li><a href="ma-linearODE.html" data-scroll="ma-linearODE">Linear ODE systems</a></li>
<li><a href="ma-exponential.html" data-scroll="ma-exponential">Matrix exponential</a></li>
</ul>
<h2 class="link"><a href="fourier-series.html" data-scroll="fourier-series"><span class="codenumber">5</span> <span class="title">Fourier series</span></a></h2>
<ul>
<li><a href="fs-orthgonality.html" data-scroll="fs-orthgonality">Main idea</a></li>
<li><a href="fs-realimag.html" data-scroll="fs-realimag">Special forms</a></li>
<li><a href="fs-convergence.html" data-scroll="fs-convergence">Convergence</a></li>
</ul>
<h2 class="link"><a href="fourier-series.html" data-scroll="fourier-series"><span class="codenumber">6</span> <span class="title">Boundary-value problems</span></a></h2>
<ul>
<li><a href="bvp-boundaries.html" data-scroll="bvp-boundaries">Boundaries</a></li>
<li><a href="bvp-eigenfunctions.html" data-scroll="bvp-eigenfunctions">Eigenfunctions</a></li>
</ul></nav><div class="extras"><nav><a class="mathbook-link" href="https://mathbook.pugetsound.edu">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="mathbook-content"><section class="section" id="ma-eigenvalues"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.6</span> <span class="title">Eigenvalues</span>
</h2>
<a href="ma-eigenvalues.html" class="permalink">¶</a><section class="introduction" id="introduction-19"><p id="p-405"><em class="emphasis">From section 6.1.</em></p>
<p id="p-406">Given a square matrix \(\bA\text{,}\) a solution of</p>
<div class="displaymath">
\begin{equation*}
\bA \bv = \lambda \bv
\end{equation*}
</div>
<p>for a scalar \(\lambda\) and a nonzero vector \(\bv\)  means that \(\lambda\) is called an <dfn class="terminology">eigenvalue</dfn> and \(\bv\) is an associated <dfn class="terminology">eigenvector</dfn>. The first thing to note is that \(c\bv\) is then an eigenvector for \(\lambda\) for any nonzero \(c\text{;}\) that is, eigenvectors are determined only up to (at most) a multiplicative scalar.</p>
<p id="p-407">Before going on to more generalities about eigenvalues, consider the implications for a linear ODE system \(\by'=\bA\by\text{.}\) We can insert the trial solution \(\by(t)=g(t) \bv\) for unknown time dependence and get</p>
<div class="displaymath">
\begin{equation*}
g'(t) \bv  =  g(t) \bA \bv = g(t) \lambda \bv\text{.}
\end{equation*}
</div>
<p>This can be satisfied by requiring \(g'=\lambda g\text{.}\) So we conclude that \(\by(t)=e^{\lambda t}\bv\) solves the original linear system. Geometrically, the eigenvector condition means "\(\bA\bv\) is parallel to \(\bv\text{.}\)" In a linear ODE, this makes \(\by'\) parallel to \(\by\text{,}\) so the direction never changes and the problem is essentially one-dimensional.</p></section><section class="subsection" id="subsection-62"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.6.1</span> <span class="title">Characteristic polynomial</span>
</h3>
<p id="p-408">The defining eigenpair condition is equivalent to \(\bA \bv = \lambda \mathbf{I} \bv, \) or</p>
<div class="displaymath">
\begin{equation*}
(\bA-\lambda \mathbf{I})  \bv = \boldsymbol{0}\text{.}
\end{equation*}
</div>
<p>Now suppose \(\lambda\) is a number such that \((\bA-\lambda \mathbf{I})\) is a nonsingular matrix. It follows that the linear system above has a unique solution, namely \(\bv = \boldsymbol{0}\text{.}\) So, we can find no eigenvector at that value of \(\lambda\text{.}\) In other words,</p>
<article class="theorem-like" id="theorem-3"><h6 class="heading">
<span class="type">Theorem</span> <span class="codenumber">4.6.1</span>
</h6>
<p id="p-409">\(\lambda\) is an eigenvalue if and only if \(\bA-\lambda \mathbf{I}\) is a singular matrix. All nonzero members of the nullspace of \(\bA-\lambda \mathbf{I}\) are eigenvectors associated with \(\lambda\text{.}\)</p></article><p id="p-410">This connection gives the most common way to compute eigenvalues by hand. Recall that a matrix is singular if and only if its determinant is zero. Thus an alternative algebraic condition for an eigenvalue is \(\det(\bA-\lambda \mathbf{I})=0\text{.}\) The eigenvectors associated with \(\lambda\) are the nonzero members of the nullspace of \(\bA-\lambda\bI\text{.}\) For an eigenvalue this space is at least one-dimensional.</p>
<p id="p-411">In the \(n\times n\) case, \(\det(\bA-\lambda\bI)\) is a polynomial of degree \(n\) called the <dfn class="terminology">characteristic polynomial</dfn> of \(\bA\text{.}\) Thus there are \(n\) eigenvalues, if we count multiplicities, i.e.,</p>
<div class="displaymath">
\begin{equation*}
\det(\bA-\lambda\bI) = (\lambda-\lambda_1)^{m_1} (\lambda-\lambda_2)^{m_2} \cdots 
(\lambda-\lambda_k)^{m_k}  \text{,}
\end{equation*}
</div>
<p>where \(k\le n\) and the positive integers \(m_i\text{,}\) called the <dfn class="terminology">algebraic multiplicities</dfn> of the eigenvalues, sum to \(n\text{.}\)</p>
<p id="p-412">Thanks to cofactor expansion of the determinant, there is one type of matrix for which finding the eigenvalues is trivial.</p>
<article class="theorem-like" id="theorem-4"><h6 class="heading">
<span class="type">Theorem</span> <span class="codenumber">4.6.2</span>
</h6>
<p id="p-413">The eigenvalues of a triangular matrix are the diagonal entries of the matrix.</p></article><p id="p-414">Diagonal matrices are included in the theorem.</p></section><section class="subsection" id="subsection-63"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.6.2</span> <span class="title">Eigensystems in the \(2\times 2\) case</span>
</h3>
<p id="p-415">The characteristic polynomial in the \(2\times 2\) situation will return us to familiar territory.</p>
<div class="displaymath">
\begin{align*}
\det( \bA -\lambda \mathbf{I} ) \amp = \det\left( \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} - \lambda \begin{bmatrix} 1 \amp 0 \\ 0 \amp 1 \end{bmatrix} \right)\\
\amp = \begin{vmatrix} a-\lambda \amp b \\ c \amp d-\lambda \end{vmatrix} = (a-\lambda)(d-\lambda)-bc=\lambda^2 - T \lambda +D\text{,}
\end{align*}
</div>
<p>where \(T\) and \(D\) are the trace and determinant of \(\bA\text{.}\) This is what I stated when we were analyzing the stability of a 2-by-2 linear ODE system.</p>
<p id="p-416">Since an eigenvalue makes \(\bA-\lambda\bI\) singular, one step of elimination on that matrix will make the second row all zeros. Thus we only need to pay attention to the condition imposed by the first row, \((a-\lambda)v_1 + b v_2 =0\text{.}\) One solution of this equation is \(\bv=\twovec{b}{\lambda-a}\text{,}\) which will be a representation of \(\mathcal{N}(\bA)\text{.}\) The only exception is if \(\lambda-a=b=0\text{,}\) in which case we need to swap rows before the elimination step.</p>
<article class="example-like" id="example-57"><a knowl="" class="id-ref" refid="hk-example-57"><h6 class="heading">
<span class="type">Example</span> <span class="codenumber">4.6.3</span>
</h6></a></article><div id="hk-example-57" class="hidden-content tex2jax_ignore"><article class="example-like"><p id="p-417">Let's find the eigenvalues and eigenvectors of</p>
<div class="displaymath">
\begin{equation*}
\begin{bmatrix} 1 \amp 1 \\ 4 \amp 1 \end{bmatrix}\text{.}
\end{equation*}
</div>
<p>The associated polynomial is \(\lambda^2-2\lambda-3\text{,}\) which has roots  \(\lambda_1=3\) and \(\lambda_2=-1\text{.}\) These are the eigenvalues.</p>
<p id="p-418">Next, the first row of the linear system \(( \bA -3 \mathbf{I}) \bv = \boldsymbol{0} \) is \(-2v_1 + 1v_2=0\text{,}\) which has nonzero solution \(\bv_1=\twovec{1}{2}\text{.}\) This eigenvector represents the entire eigenspace for \(\lambda_1\text{.}\) Similarly, for \(\lambda_2=-1\) the first row of the null system is \(2v_1+v_2=0\text{,}\) so \(\bv_2 = \twovec{1}{-2}\) represents that eigenspace.</p></article></div>
<p id="p-419">Quick note: We often speak of "finding the eigenvalues and eigenvectors" of a matrix. The eigenvalues are unique, but eigenvectors are not. What's really meant is to find minimal representations of the eigenspaces, which are uniquely determined, but that's just considered understood.</p>
<article class="example-like" id="example-58"><a knowl="" class="id-ref" refid="hk-example-58"><h6 class="heading">
<span class="type">Example</span> <span class="codenumber">4.6.4</span>
</h6></a></article><div id="hk-example-58" class="hidden-content tex2jax_ignore"><article class="example-like"><p id="p-420">Consider \(\bA=\twomat{4}{0}{1}{4}\text{.}\) This matrix is (lower) triangular, so we immediately know \(\lambda_1=\lambda_2=4\text{.}\) Now,</p>
<div class="displaymath">
\begin{equation*}
\bA - 4\bI = \twomat{0}{0}{1}{0}\text{.}
\end{equation*}
</div>
<p>If we swap the rows, the matrix is in RE form. Hence \(v_2\) is free and \(v_1=0\text{.}\) The eigenspace is one-dimensional, fully represented by \(\twovec{0}{1}\text{.}\)</p></article></div></section><section class="subsection" id="subsection-64"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.6.3</span> <span class="title">Complex eigenvalues</span>
</h3>
<p id="p-421">The connection to polynomials means that if \(\bA\) is a real matrix, it might have eigenvalues that occur in complex conjugate pairs. This makes the eigenvectors have the same structure.</p>
<article class="example-like" id="example-59"><a knowl="" class="id-ref" refid="hk-example-59"><h6 class="heading">
<span class="type">Example</span> <span class="codenumber">4.6.5</span>
</h6></a></article><div id="hk-example-59" class="hidden-content tex2jax_ignore"><article class="example-like"><p id="p-422">We find the eigenvalues and eigenvectors of</p>
<div class="displaymath">
\begin{equation*}
\begin{bmatrix} 1 \amp -1 \\ 5 \amp -3 \end{bmatrix}\text{.}
\end{equation*}
</div>
<p>The characteristic polynomial is \(\lambda^2 +2 \lambda +2\text{,}\) with roots  \(\lambda_{1,2} = -1 \pm 1i.\)</p>
<p id="p-423">To find an eigenvector for \(\lambda_1\text{,}\) we use the first row of \(\bA - \lambda_1 \mathbf{I} \) to conclude \((2-i)v_1 -v_2 = 0\text{.}\) Thus any nonzero multiple of \(\bv_1=\twovec{1}{2-i}\) will do.</p>
<p id="p-424">We get a benefit here from the complex eigenvalues: the conjugate of an eigenvector will be an eigenvector for the conjugated eigenvalue. So we have \(\bv_2=\twovec{1}{2+i}\) to go with \(\lambda_2\text{.}\)</p></article></div></section><section class="subsection" id="subsection-65"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.6.4</span> <span class="title">Some tips</span>
</h3>
<p id="p-425">Here are a couple of things to know: the eigenvalues of \(\bA+\bB\) are <em class="emphasis">not</em>  the eigenvalues of \(\bA\) plus the eigenvalues of \(\bB\text{,}\) and the eigenvalues of \(\bA\bB\) are <em class="emphasis">not</em>  the eigenvalues of \(\bA\) times the eigenvalues of \(\bB\text{.}\) The main exception to this latter observation is for powers of a matrix,</p>
<div class="displaymath">
\begin{equation*}
\bA \bv = \lambda \bv \quad \Rightarrow \quad \bA^k \bv = \lambda^k \bv\text{,}
\end{equation*}
</div>
<p>for any positive integer power \(k\text{.}\)  Actually, this holds for inverses too,</p>
<div class="displaymath">
\begin{equation*}
\bA \bv = \lambda \bv \quad \Rightarrow \quad \bA^{-1} \bv = \lambda^{-1} \bv\text{.}
\end{equation*}
</div>
<p>(Note that if zero is an eigenvalue, then \(\bA-0\bI\) is singular, so \(\bA\) is singular.)</p>
<p id="p-426">Two other handy facts hold for matrices of all sizes.</p>
<article class="theorem-like" id="fact-6"><h6 class="heading">
<span class="type">Fact</span> <span class="codenumber">4.6.6</span>
</h6>
<p id="p-427">The sum of the eigenvalues of \(\bA\) is the <dfn class="terminology">trace</dfn> of \(\bA\) (sum of the diagonal entries).</p></article><article class="theorem-like" id="fact-7"><h6 class="heading">
<span class="type">Fact</span> <span class="codenumber">4.6.7</span>
</h6>
<p id="p-428">The product of the eigenvalues is the determinant.</p></article></section></section></div></main>
</div>
</body>
</html>
