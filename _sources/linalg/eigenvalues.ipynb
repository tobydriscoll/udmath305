{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "emerging-brighton",
   "metadata": {},
   "source": [
    "# Eigenvalues\n",
    "\n",
    "The last stop on our whirlwind tour of linear algebra is the hardest to motivate for a little while. However, the topic is important to the differential equations we study in future chapters, in the sense of oxygen being an important part of breathing.\n",
    "\n",
    "We are still operating with square matrices only.\n",
    "\n",
    "(definition-linalg-eigen)=\n",
    "\n",
    "````{proof:definition} Eigenvalue and eigenvector\n",
    "\n",
    "Suppose $\\bfA\\in\\cmn{n}{n}$. If there exist a scalar $\\lambda$ and a nonzero vector $\\bfv$ such that\n",
    "\n",
    "```{math}\n",
    "\\bfA \\bfv = \\lambda \\bfv,\n",
    "```\n",
    "\n",
    "then $\\lambda$ is an {term}`eigenvalue` of $\\bfA$ with associated {term}`eigenvector` $\\bfv$.\n",
    "````\n",
    "\n",
    "If you think of $\\bfA$ as acting on vectors, then an eigenvector is a direction in which the action of $\\bfA$ is the same as a scalar; we have found a little one-dimensional oasis in which the behavior of $\\bfA$ is easy to comprehend.\n",
    "\n",
    "## Eigenspaces\n",
    "\n",
    "An eigenvalue is a clean, well-defined target. Eigenvectors are a little slipperier. For starters, if $\\bfA\\bfv=\\lambda\\bfv$, then\n",
    "\n",
    "```{math}\n",
    "\\bfA(c\\bfv) = c(\\bfA\\bfv)=c(\\lambda\\bfv)=\\lambda(c\\bfv).\n",
    "```\n",
    "\n",
    "```{note}\n",
    "Every nonzero multiple of an eigenvector is also an eigenvector for the same eigenvalue.\n",
    "```\n",
    "\n",
    "But there can be even more ambiguity than scalar multiples.\n",
    "\n",
    "::::{admonition} Example\n",
    ":class: tip\n",
    "\n",
    "Let $\\meye$ be an identity matrix. Then $\\meye\\bfx=\\bfx$ for any vector $\\bfx$, so every nonzero vector is an eigenvector!\n",
    "::::\n",
    "\n",
    "Fortunately we already have the tools we need to describe a more robust target, based on the very simple reformulation\n",
    "\n",
    "```{math}\n",
    "\\bfzero=\\bfA\\bfv-\\lambda\\bfv=(\\bfA-\\lambda\\meye)\\bfv.\n",
    "```\n",
    "\n",
    "(definition-linalg-eigenspace)=\n",
    "\n",
    "````{proof:definition} Eigenspace\n",
    "Let $\\lambda$ be an eigenvalue of $\\bfA$. The {term}`eigenspace` associated with $\\lambda$ is the general solution of $(\\bfA-\\lambda\\meye)\\bfx = \\bfzero$.\n",
    "````\n",
    "\n",
    "Eigenspaces, unlike eigenvectors, are unique. We have to be a bit careful, though, because we usually express such spaces using basis vectors, and those bases are not themselves unique. It's also not unusual for problems and discussions to use eigenvectors and just put up with the nonuniqueness.\n",
    "\n",
    "## Computing eigenvalues and eigenvectors\n",
    "\n",
    "Note that if $\\lambda$ is *not* an eigenvalue, then by definition the only solution of $(\\bfA-\\lambda\\meye)\\bfv=\\bfzero$ is $\\bfv=\\bfzero$. That requires $\\bfA-\\lambda\\meye$ to be invertible.\n",
    "\n",
    "````{proof:theorem}\n",
    "$\\lambda$ is an eigenvalue of $\\bfA$ if and only if $\\bfA-\\lambda\\meye$ is singular.\n",
    "````\n",
    "\n",
    "In practice the most common way to find eigenvalues by hand is through the equivalent condition $\\det(\\bfA-\\lambda\\meye)=0$. This determinant has a particular form and name.\n",
    "\n",
    "```{proof:definition} Characteristic polynomial of a matrix\n",
    "Suppose $\\bfA$ is an $n\\times n$ matrix. The function $p(z) = \\det(\\bfA-z\\meye)$ is a polynomial of degree $n$ in $z$, known as the {term}`characteristic polynomial` of $\\bfA$.\n",
    "```\n",
    "\n",
    "````{proof:algorithm} Eigenvalues and eigenspaces\n",
    "Given an $n\\times n$ matrix $\\bfA$:\n",
    "\n",
    "1. Find the characteristic polynomial $p$ of $\\bfA$.\n",
    "2. Let $\\lambda_1,\\ldots,\\lambda_k$ be the distinct roots of $p$. These are the eigenvalues. (If $k<n$, it's because one or more roots has multiplicity greater than 1.)\n",
    "3. For each $\\lambda_j$, find the general solution of $(\\bfA-\\lambda_j\\meye)\\bfv=\\bfzero$. This is the eigenspace associated with $\\lambda_j$.\n",
    "````\n",
    "\n",
    "::::{admonition} Example\n",
    ":class: tip\n",
    "Find the eigenvalues and eigenspaces of\n",
    "\n",
    "```{math}\n",
    "\\bfA = \\begin{bmatrix} 1 & 1 \\\\ 4 & 1 \\end{bmatrix}.\n",
    "```\n",
    "\n",
    ":::{dropdown} Solution\n",
    "Start by computing the characteristic polynomial:\n",
    "\n",
    "```{math}\n",
    "\\det \\left(\\twomat{1}{1}{4}{1} - \\twomat{\\lambda}{0}{0}{\\lambda} \\right) = \\twodet{1-\\lambda}{1}{4}{1-\\lambda} = (1-\\lambda)^2 - 4 = \\lambda^2-2\\lambda-3.\n",
    "```\n",
    "\n",
    "We find eigenvalues by finding its roots, in this case $\\lambda_1=3$ and $\\lambda_2=-1$. \n",
    "\n",
    "For $\\lambda_1=3$,\n",
    "\n",
    "```{math}\n",
    "\\bfA-3 \\meye = \\twomat{-2}{1}{4}{-2} \\quad \\overset{\\text{RREF}}{\\Longrightarrow} \\quad \\twomat{1}{-1/2}{0}{0}.\n",
    "```\n",
    "\n",
    "The homogeneous solution can be expressed as $x_1=s/2$, $x_2=s$, or $\\bfx=s\\cdot[1/2;\\,1]$. So $[1/2;\\,1]$ is a basis for this eigenspace. Since eigenvectors can be rescaled at will, we prefer to use $\\twovec{1}{2}$ as the basis vector.\n",
    "\n",
    "For $\\lambda_2=-1$,\n",
    "\n",
    "```{math}\n",
    "\\bfA+ \\meye = \\twomat{2}{1}{4}{2} \\quad \\overset{\\text{RREF}}{\\Longrightarrow} \\quad \\twomat{1}{1/2}{0}{0},\n",
    "```\n",
    "\n",
    "leading to the eigenspace basis $[-1/2;\\,1]$ or equivalently, $\\twovec{-1}{2}$.\n",
    ":::\n",
    "::::\n",
    "\n",
    "## MATLAB\n",
    "\n",
    "MATLAB computes eigenvalues (through an entirely different process) with the `eig` command. From the preceding example, for instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worse-flooring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    '9.7.0.1296695 (R2019b) Update 4'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lambda =\n",
      "\n",
      "   3.000000000000000\n",
      "  -1.000000000000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = [ 1 1; 4 1 ];\n",
    "lambda = eig(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-flavor",
   "metadata": {},
   "source": [
    "If you want eigenvectors as well, use an alternate form for the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bearing-attention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "V =\n",
      "\n",
      "   0.447213595499958  -0.447213595499958\n",
      "   0.894427190999916   0.894427190999916\n",
      "\n",
      "\n",
      "D =\n",
      "\n",
      "   3.000000000000000                   0\n",
      "                   0  -1.000000000000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "[V,D] = eig(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-lancaster",
   "metadata": {},
   "source": [
    "In most cases, column `V(:,k)` is an eigenvector for the eigenvalue `D(k,k)`. (For eigenvalues of multiplicity greater than 1, the interpretation can be more complicated.) Keep in mind that any scalar multiple of an eigenvector is equally valid.\n",
    "\n",
    "## Eigenvectors for $2\\times 2$\n",
    "\n",
    "Finding the exact roots of a cubic polynomial is not an easy matter unless the polynomial is special. Thus most of our hand computations will be with $2\\times 2$ matrices. Suppose $\\lambda$ is known to be an eigenvalue of $\\bfA$. Then $\\bfA-\\lambda\\meye$ must be singular, and its RREF has at least one free column. Hence row elimination will zero out the second row entirely, and we can ignore it. That allows us to deduce the following.\n",
    "\n",
    "```{proof:algorithm} Eigenvectors for $2\\times 2$\n",
    "1. Let $\\lambda$ be an eigenvalue of $\\bfA$.\n",
    "2. Let the first row of $\\bfA-\\lambda\\meye$ be designated by $[\\alpha,\\beta]$. \n",
    "    - If $\\alpha=\\beta=0$, then $\\bfA-\\lambda\\meye$ is a zero matrix and all of $\\complex^2$ is the eigenspace of $\\lambda$.\n",
    "    - Otherwise, the vector $[\\beta;\\,-\\alpha]$ is a basis of the eigenspace of $\\lambda$.\n",
    "```\n",
    "\n",
    "::::{admonition} Example\n",
    ":class: tip\n",
    "Find the eigenstuff of \n",
    "\n",
    "```{math}\n",
    "\\bfA = \\twomat{1}{1}{-1}{1}.\n",
    "```\n",
    ":::{dropdown} Solution\n",
    "We start by finding eigenvalues. \n",
    "\n",
    "$$\n",
    "\\det(\\bfA - \\lambda \\meye) = \\twodet{1-\\lambda}{1}{-1}{1-\\lambda} = (1-\\lambda)^2 + 1.\n",
    "$$\n",
    "\n",
    "The eigenvalues are therefore roots of $\\lambda^2 - 2\\lambda + 2$, or \n",
    "\n",
    "$$\n",
    "\\lambda = 1 \\pm \\sqrt{1-2} = 1 \\pm i.\n",
    "$$\n",
    "\n",
    "This is our first case of a real matrix that has complex eigenvalues. We continue as always, only using complex arithmetic.\n",
    "\n",
    "The eigenspace for $\\lambda_1=1+i$ is the homogeneous solution of \n",
    "\n",
    "$$\n",
    "\\bfA - (1+i) \\meye = \\twomat{-i}{1}{-1}{-i}.\n",
    "$$\n",
    "\n",
    "To find a basis we just use the first row as explained above, getting $\\twovec{1}{i}$. \n",
    "\n",
    "Now we get a nice reward for using complex numbers. Since the matrix is real, the other eigenvalue is the conjugate of $\\lambda_1$, and it turns out that the same is true of the eigenspace as well. So $\\twovec{1}{-i}$ is a basis for the second eigenspace.\n",
    ":::\n",
    "::::\n",
    "\n",
    "   <div style=\"max-width:608px\"><div style=\"position:relative;padding-bottom:66.118421052632%\"><iframe id=\"kaltura_player\" src=\"https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&playerId=kaltura_player&entry_id=1_2wzgw5dv&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_e9ee2yk9\" width=\"608\" height=\"402\" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow=\"autoplay *; fullscreen *; encrypted-media *\" sandbox=\"allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation\" frameborder=\"0\" title=\"Kaltura Player\" style=\"position:absolute;top:0;left:0;width:100%;height:100%\"></iframe></div></div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.12",
    "jupytext_version": "1.5.0"
   }
  },
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.16.11"
  },
  "source_map": [
   14,
   132,
   135,
   139,
   141
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}