<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="ch5-nonlinear-ode" xmlns:xi="http://www.w3.org/2001/XInclude">
<title>Nonlinear ODEs</title>
<introduction>
	<p>
		Given how much we have invested in understanding linear equations and systems, it may be a shock to realize that they pale in comparison to the possibilities in nonlinear problems. In a linear problem we can say a lot about the structure of solutions, and we do have solution formulas, though we may not be able to carry them out in closed form. 
	</p>
	<p>
		By contrast, nonlinear problems don't even always have solutions, or unique ones. Even for those that do, calculating the solution exactly is more the exception than the rule. Hence we use other tools to draw some conclusions about the solutions of many problems.  
	</p>
	<p>
		As with linear problems, nonlinear ODEs of order higher than one can be converted to first-order problems in a higher dimension. Therefore we can organize the discussion entirely around first-order problems. In the first few sections we limit ourselves to scalar (or one-dimensional) problems in the form <m>x'=f(t,x)</m>. Then we turn our attention to systems of two equations in two variables. The extension to still higher dimensions is closely related, but more complicated.
	</p>
</introduction>

<section xml:id="nl-overview">
	<title>Overview of nonlinear problems</title>
	<p>
		Nonlinear problems are not a matter of <q>like linear, but harder</q>. They have less predictable structure; we have to set aside the idea of superposition of homogeneous and particular solutions, for example. Indeed, many nonlinear problems are not solvable even in principle. 
	</p>
	<example>
		<p>
			In <xref ref="ex-nonlinear-growth"/> it was brought up that the ODE <m>x'=x^2</m> has solutions that blow up at a finite time. In fact, the solution with <m>x(0)=x_0</m> is <m>x(t)=x_0/(1-x_0t)</m>, which is infinite at <m>t=1/x_0</m>. By contrast, linear problems are guaranteed to have solutions wherever their coefficient and forcing functions are continuous. 
		</p>
	</example>
	<example>
		<p>
			One solution of the IVP <m>x'=2\sqrt{x}</m>, <m>x(0)=0</m> is <m>x(t)=t^2</m>. But so is the constant function <m>x(t)\equiv 0</m>. In fact, so is <m>x(t)=H(t-T)(t-T)^2</m> for any positive delay <m>T</m>. Hence we cannot automatically expect unique solutions to nonlinear initial-value problems. 
		</p>
	</example>
	<aside>
		<p>
			When time is reversed, <m>x'=2\sqrt{x}</m> is equivalent to <em>Toricelli's Law</em> governing the emptying of a bucket with a small hole in the bottom. An interpretation of the nonuniqueness observation is that if you come across an empty leaky bucket, there is no way to know when, if ever, it held water!
		</p>
	</aside>
	<p>
		There are some ways to guarantee the existence and uniqueness of solutions, but the conclusions are limited and the circumstances do not apply to all or perhaps even most problems of interest. We do not describe them here.
	</p>
	<p>
		The tools for nonlinear problems are more numerous yet less comprehensive than for linear problems: 
		<dl>
		  <li>
			<title>Special cases</title>
			<p>
				There are problem types that allow successful solution strategies. One of these types, <em>separable equations</em>, is likely already familiar to you. Others include <em>exact equations</em> and <em>Ricatti	equations</em>.  
			</p>
		  </li>
		  <li>
			<title>Change of variables</title>
			<p>
				As with integration, a change of variables (independent or dependent) can transform a system from a puzzle to a solvable equation. Occasionally there are reasons behind trying certain substitutions, but they often seem to appear out of nowhere. 
			</p>
		  </li>
		  <li>
			<title>Approximations</title>
			<p>
				The most-often used approximation method is <em>linearization</em>, which lets us call on the methods we have discussed to this point. Other situations are large-time and small-parameter approximations, in the domain of <em>asymptotics</em>. 
			</p>
		  </li>
		  <li>
			  <title>Qualitative methods</title>
			<p>
				Even if it is not possible to write out a solution formula, there are techniques from topology, geometry,  and other areas of mathematics that allow us to deduce some specific major properties of the solutions. A notable example is <em>bifurcation analysis</em>, which studies the effects of a key parameter. 
			</p>
		  </li>
		  <li>
			<title>Numerical solutions</title>
			<p>
				Numerical solutions are the most universally available methods. They are a form of approximation, though for routine practical applications they can usually be much more accurate than other sources of error or uncertainty would allow. There are circumstances, however, such as very long times or chaotic systems, in which there is some subtlety to the interpretation of numerical results. 
			</p>
		  </li>
		</dl>
	</p>
	
</section>
<section xml:id="nl-scalar">
	<title>Scalar first-order problems</title>
	<introduction>
		<p>
			Scalar, first-order nonlinear problems are often more penetrable than more general equations. If nothing else, the problem 
			<me>
				x' = f(t,x)
			</me>
			is easily visualized. By evaluating <m>f</m> on a grid in the <m>(t,x)</m> plane, we can draw arrows representing the slope <m>dx/dt</m> of the solution curves that pass through the grid points. This picture is known as a <idx>direction field</idx><term>direction field</term>. 
		</p>
		<example>
			<title>Direction field for a scalar problem</title>
			<p> 
				Here is a direction field for <m>x'=t-x^2</m>. Note that the arrows are horizontal along the sideways parabola <m>t=x^2</m>. Curves with this property are known as <term>nullclines</term>.
			</p>
			<sidebyside>
				<listing xml:id="nl_dirfield_3">
				<program language="matlab">
				<input>
				f = @(t,x) t-x^2;
				slopefield(f,[-2 2],[-2 2])
				</input>
				</program>
				</listing>
				<image source="figures/nl_dirfield_3.svg"/>
			</sidebyside>
		</example>
	</introduction>
	<subsection xml:id="nl-sec-autonomous">
		<title>Autonomous equations</title>
		<p>
			Problems of the form <m>x'=f(x)</m> are called <idx>autonomous ODE</idx><term>autonomous</term>. In autonomous problems, a root of the function <m>f</m> is an <idx>equilibrium</idx> equilibrium or steady-state solution. As we saw in linear systems, the stability of equilibrium solutions is often important. 
		</p>
		<p>
			The direction field of an autonomous equation is independent of <m>t</m>. A different picture known as a <idx>phase line diagram</idx><term>phase line diagram</term> can help to discriminate between stable and unstable equilibria. This is most readily explained with an example. 
		</p>
		<example>
			<p>
				Consider the ODE <m>x'=x-x^3</m>. The equilibrium solutions are <m>x=0</m> and <m>x=\pm 1</m>, which is clear in a plot of <m>f(x)</m>. The plot also shows the sign of <m>f(x)</m> and therefore of <m>dx/dt</m>. So between the equilibria we can draw arrows to show whether <m>x</m> is increasing or decreasing with time. The arrows clarify that the steady states at <m>x=\pm 1</m> are stable, while the one at <m>x=0</m> is unstable.
			</p>
			<sidebyside>
				<listing xml:id="nl_phaseline">
					<caption>Phase-line diagram</caption>
					<program language="matlab">
						<input>
f = @(x) x - x.^3;
fplot(f,[-1.5,1.5])
set(gca,'xaxisloc','origin')
xlabel x, ylabel f(x)
hold on, ylim([-1 1]), axis equal
tt = [-1.35 -0.4 0.4 1.35];
quiver(tt,0*tt,0.15*[1 -1 1 -1],0*tt,.2,'linew',2) 
						</input>
					</program>
				</listing>
				<image source="figures/nl_phaseline.svg"/>
			</sidebyside>
		</example>		 
		<p>
			A simple analytical test for the stability of an equilibrium value <m>x_e</m> is that <m>f'(x_e) \lt 0</m> at a stable equilibrium, and <m>f'(x_e) \gt 0</m> at an unstable one. This too is clear from the phase-line diagram. The case <m>f'(x_e)=0</m> requires additional investigation. 
		</p>
	</subsection>
	
	<subsection xml:id="nl-separable">
		<title>Separable equations</title>
		<p>
		All problems in the autonomous form <m>x'=f(x)</m>, and more generally in the form <m>x'=f(x)g(t)</m>, are called <idx>separable ODE</idx><term>separable equations</term> and can be solved systematically (up to performing integrations). Rather than deriving a formula for them, it's best to just repeat a straightforward process for each new problem.
	</p>
	
	<example>
		<p>
			Consider the <xref ref="ex-variable-growth">variable growth archetype</xref> <m>x'=2tx</m>. We express <m>x'</m> as <m>dx/dt</m> and then isolate the variables:
			<me>
				\frac{dx}{x} = 2t\,dt
			</me>.
			Integrating both sides leads to <m>\log |x| = t^2 + C</m>, or <m>|x|=Ae^{t^2}</m> for a positive constant <m>A</m> (since it is the exponential of a real constant). Taking the absolute value off of <m>x</m> means that <m>A</m> can be negative as well. Also, <m>A=0</m> clearly leads to a solution. Finally, we conclude that <m>x=Ce^{t^2}</m> for arbitrary <m>C</m>.
		</p>
	</example>
	
	<example>
		<p>
			Suppose <m>x'=t^2/(x^3-2)</m>. Separation and integration lead to
			<me>
				\int (x^3-2) \, dx = \int t^2\, dt
			</me>,
			or <m>\frac{1}{4}x^4 - 2x  = C + \frac{1}{3}t^3</m>. We could work hard to try to solve explicitly for <m>y</m>, but it's probably best to leave it in implicit form. This is a common limitation to separable "solutions".
		</p>
		<p>
			Even in implicit form, we can solve for the arbitrary constant if given an initial condition. For instance, suppose <m>x(0)=4</m> is given for this ODE. Then <m>4^4/4-2\cdot4 = C+0</m>, so <m>C=56</m>.
		</p>
	</example>
	<p>
		Sometimes the separable structure isn't immediately apparent, and you have to manipulate the expressions a bit.
	</p>
	<example>
		<p>
			Suppose <m>t x' = x-t x</m>. This does not look separable until you see that you can factor out <m>x</m> on the right side. Then we have <m>dx/dt = x(1-t)/t</m>, or
			<me> \frac{dx}{x} = (t^{-1}-1)\,dt</me>.
			Thus <m>\ln|x| = \ln|t|-t+C</m>, or <m>x=A t e^{-t}</m>. 
		</p>
		<p>
			Note that this problem is also linear, so it could be approached that way as well. Of course you must get the same solution in the end!
		</p>
	</example>	
</subsection>

<exercises xml:id="nl-exer-separation">
	<exercise>
		<title>Change of variable</title>
		<statement>
			<p>
				The equation 
				<me>
					x' = x + t x^2 
				</me>
				is neither linear nor separable. However, show that the change of variable <m>u=x^{-1}</m> transforms it into 
				<me>
					u' + u = -t
				</me>,
				which is linear. Solve this equation and then use that to solve the original ODE. 
			</p>
		</statement>
		<answer>
		  <p>
			<m>x = \dfrac{1}{c_1 e^{-t} + 1 - t}</m>
		  </p>
		</answer>
		<solution>
		  <p>
			With <m>u=x^{-1}</m>, we have 
			<me>
				\dd{u}{t} = \dd{u}{x}\,\dd{x}{t} = -x^{-2} \dd{x}{t}.
			</me>
			From this the original ODE becomes 
			<md>
			  <mrow> -x^2 u' \amp = x + t x^2 </mrow>
			  <mrow> u' \amp = -x{-1} - t,</mrow>
			</md>
			which gives <m>u'+u=-t</m>. This has particular solution <m>u_p=At+B</m>, and we quickly find <m>u_p=1-t</m>. Hence the general solution is 
			<m>
				u = c_1 e^{-t} + 1 - t, 
			</m>
			and therefore 
			<me>
				x = \frac{1}{c_1 e^{-t} + 1 - t}.
			</me>
			This is a special case of a <em>Bernoulli equation</em>. 
		  </p>
		</solution>
	</exercise>
	<exercise>
		<title>Flames in space</title>
		<statement>
		  <p>
			A simple model for the radius of a ball of flame in zero gravity is <m>r'=r^2-r^3</m>, because oxygen intake is proportional to surface area while fuel consumption is proportional to volume. Find an implicit solution of this equation. 
		  </p>
		</statement>
		<answer>
		  <p>
			  <me>
				  \log\left(\frac{r}{1-r}\right) - \frac{1}{r} = t + c_1
			  </me>
		  </p>
		</answer>
	</exercise>
</exercises>
<solutions divisional="solution"></solutions>
</section>

<section xml:id="nl-logistic">
	<title>Case study: Logistic equation</title>
	<introduction>
	<p>
		Say <m>x(t)</m> represents a population of bacteria. (There is always a whole number of bacteria, of course, but we'll allow real values. For large numbers that shouldn't matter.) If we assume that each bacterium produces offspring and ages at a constant rate, the result is a constant <em>net per capita growth rate</em>:
		<me>
			\frac{1}{x} \dd{x}{t} = a
		</me>.
		If <m>a\gt 0</m>, then this is a recipe for exponential growth, a la <m>x'=ax</m>. 
	</p>

	<p>
		There are a lot of assumptions behind that model, but perhaps the most glaringly suspect one is that it supposes an endless supply of food and space, allowing population to grow without bound, forever. An improved model would decrease the per capita rate as the population increases. The simplest way to do so is to let <m>b\gt 0</m> be another positive parameter, and define
		<me>
			\frac{1}{x} \dd{x}{t} = a - bx, \qquad \text{or} \qquad \dd{x}{t} = ax - bx^2 
		</me>.
		This is the <idx>logistic equation</idx><term>logistic equation</term>. It's useful to define <m>K=a/b</m> and rewrite the model as 
		<men xml:id="eq-logistic">
			\dd{x}{t} = ax\left(1 - \frac{x}{K}\right)  
		</men>.
		Both parameters are positive. The parameter <m>K</m> is known as the <idx>carrying capacity</idx><term>carrying capacity</term> and plays an important role. 
	</p>
	</introduction>

	<subsection xml:id="nl-lo-steady">
		<title>Steady states</title>
		<p>
			We begin with the steady states, which from <xref ref="eq-logistic"/> are clearly <m>x=0</m> and <m>x=K</m>. Since <m>f'(x)=a-(2ax/K)</m>, we conclude that the former steady state is unstable and the latter is stable. That is, the system has a tendency to hover near the carrying capacity. (Later we will show much more: this value is the long-term fate of the system for any positive initial condition.)
		</p>
		<p>
			We can get creative and show that the halfway value <m>x=K/2</m> is also special. Still without knowing explicitly what <m>x</m> is, we can differentiate the ODE and use the chain rule to obtain
			<me>
				x'' = ax'- \frac{2a x x'}{K} = ax'\left( 1 - \frac{2x}{K} \right)
			</me>.
			This is zero for <m>x=K/2</m>, suggesting that this solution value is an inflection point. 
		</p>
	</subsection>

	<subsection xml:id="fn-nl-easy">
		<title>First solution method: Substitution</title>
		<p>
			When it comes to solving nonlinear ODEs, we take success wherever we can find it. One source of <q>lucky</q> solutions is the idea of variable substitution, and the logistic equation is a nice case study. Define <m>z=1/x</m>. From the chain rule we have <m>x'=-x^{-2}x'=-x'z^2</m>. The logistic equation converts to
			<me>
				-\frac{z'}{z^2} = \frac{a}{z} - \frac{b}{z^2}
			</me>,
			or <m>z'=b-az</m>. This is a linear equation! It even has constant coefficients. In terms of <m>z</m>, we can jump right to the solution:
			<me>
				z(t) = e^{-at}z(0) - \frac{b}{a} \left( e^{-at}-1 \right) = \frac{e^{-at}(Kz_0-1)+1}{K}
			</me>.
			Finally, with <m>x=1/z</m> we get
			<men xml:id="eq-logistic-solution">
				x(t) = \frac{Kx_0}{e^{-at}(K-x_0)+x_0}
			</men>,
			where <m>x_0=x(0)</m>. 
		</p>
		<p>
			The solution formula makes it clear that <m>x\to K</m> as <m>t\to \infty</m>, if <m>x_0\gt 0</m>. If the system starts below the inflection at <m>x=K/2</m>, then the solution is an S-shaped or <em>sigmoidal</em> curve. 
		</p>
		<example>
		<sidebyside>
			<listing xml:id="fn_lo_solutions">
			<program language="matlab">
			<input>
			a = 6; b = 2;
			K = a/b;

			f = @(t,x) a*x - b*x^2;
			t = linspace(0,2.5,300);
			for x0 = K*[0.02 0.15 0.4 0.8 1.2 1.5]
				[t,x] = ode45(f,t,x0);
				plot(t,x), hold on
			end
			xlabel('t'), ylabel('x(t)')
			set(gca,'ygrid','on',...
			'ytick',K*(0:.25:1),'yticklabel',{'0','','0.5K','','K'})
			</input>
			</program>
		</listing>
		<image source="figures/fn_lo_solutions.svg"/>	  
		</sidebyside>
		</example>
	</subsection>

	<subsection xml:id="fn-lo-separate">
		<title>Second solution method: Separation</title>
		<p>
			The logistic equation is separable: 
			<me>
				\frac{dx}{x(a-bx)} = dt
			</me>.
			Hence
			<me> 
				t + C = \int \frac{dx}{x(a-bx)} = \frac{1}{b} \int \frac{dx}{x(K-x)} = \frac{1}{bK} \int \left( \frac{1}{x} + \frac{1}{K-x} \right)\,dx
			</me>.
			The last step above required converting the single fraction into partial fractions. These are now easily integrated to get logs, and the solution follows from there. Obviously we have to end up with <xref ref="eq-logistic-solution"/> again. 
		</p>
	</subsection>

	<subsection xml:id="nl-predation">
		<title>Predation</title>
		<p>
			Suppose we complicate the model by adding in the effect of a predator:
			<me>
				\frac{1}{x} \, \dd{x}{t} = a\left(1 - \frac{x}{K}\right) - p(x)
			</me>,
			where <m>p(x)</m> predation per capita. A simple model of predation as increasing from zero to a fixed saturation value as <m>x</m> changes from zero to infinity is 
			<me>
				\dd{x}{t} = ax\left(1 - \frac{x}{K}\right) - \frac{x^2}{1+x^2}
			</me>. 
			There is always a fixed point at <m>x=0</m>. Any others are determined by the intersections of a linear function with <m>p(x)</m>: 
			<me>
				a \left(1 - \frac{x}{K}\right) = \frac{x}{1+x^2}
			</me>. 
			There are two major possibilities. For small enough <m>K</m>, there is just one fixed point, as shown in <xref ref="nl-fig-logpred_small"/>. The origin is unstable and the other fixed point is stable. When <m>K</m> is sufficiently large, there are three fixed points in addition to the origin, as shown in <xref ref="nl-fig-logpred_large"/>. The origin is still stable, as is the middle of the three positive fixed points. The other two fixed points are stable. The model suggests we might observe either a low-population or high-population steady state in this scenario. 
		</p>
		<figure xml:id="nl-fig-logpred_small">
			<caption>Logistic growth with predation, small carrying capacity. The intersection of the dashed curves leads to a stable fixed point in the phase line diagram.</caption>
			<image source="figures/nl_logpred_small.svg">
				<description>diagram</description>
			</image>
		</figure>
		<figure xml:id="nl-fig-logpred_large">
			<caption>Logistic growth with predation, large carrying capacity. The intersections of the dashed curves lead to three positive fixed points of alternating stability character.</caption>
			<image source="figures/nl_logpred_large.svg">
				<description>Logistic growth with predation</description>
			</image>
		</figure>
	</subsection>
	<exercises xml:id="nl-exer-logistic">
		<exercise>
			<title>Threshold model</title>
			<statement>
				<p>
					An alternative population model is 
					<me>
						x' = -ax\left(1-\frac{x}{T}\right),
					</me>
					for positive parameters <m>a,T</m>. Show that in this model the origin is a stable equilibrium and <m>x=T</m> is an unstable one. Then find the solution and describe all the possible different behaviors from positive initial conditions as <m>t\to\infty</m>. 
				</p>
			</statement>
			<answer>
				<p>
					Either <m>x\to 0</m> or <m>x\to\infty</m> (aka <q>doomsday</q>). 
				</p>
			</answer>
		</exercise>
		<exercise>
			<title>Logistic with threshold</title>
			<statement>
				<p>
					The model 
					<me>
						x' = -ax\left(1-\frac{x}{T}\right)\left(1-\frac{x}{K}\right)
					</me>
					with positive parameters and <m>T \lt K</m> combines logistic and threshold features. Show that the origin and <m>x=K</m> are stable equilibria, while <m>x=T</m> is unstable. 
				</p>
			</statement>
			<hint>
				<p>
					This is most easily done by looking at <m>f'</m>, where <m>x'=f(x)</m>, rather than attempting a phase line diagram. 
				</p>
			</hint>
		</exercise>
		<exercise>
			<title>Gompertz growth</title>
			<statement>
				<p>
					The logistic model posits a linear decrease in the per capita growth rate as the population increases: 
					<me>
						\frac{1}{x} \, \dd{x}{t} = a\left(1 - \frac{x}{K}\right)   
					</me>.
					But there are many cases where we might have an even faster decrease in the growth rate. One such case is the <em>Gompertz equation</em>, 
					<me>
						\frac{1}{x} \, \dd{x}{t} = a\left(1 - \frac{\log(x)}{\log(K)}\right)  
					</me>.
					It has been suggested as a model for the growth of tumors. Show that the solution is 
					<me>
						x = K \exp\left[ -c_1 \exp \Bigl( - at/\log(K) \Bigr) \right],
					</me>
					for a nonnegative <m>c_1</m>. 
				</p>
			</statement>
			<hint>
				<p>
					One approach is to define <m>u=\log(x)</m> and derive a linear ODE for <m>u</m>.
				</p>
			</hint>
		</exercise>
	</exercises>
	<solutions divisional="solution"></solutions>

</section>

<section xml:id="nl-twodim">
	<title>Two-dimensional systems</title>
	<introduction>
		<p>
			An autonomous system in two dimensions has the particular form 
			<mdn>
				<mrow xml:id="nl-eq-system1"> \dd{x_1}{t} \amp = f_1(x_1,x_2), </mrow>
				<mrow xml:id="nl-eq-system2"> \dd{x_2}{t} \amp = f_2(x_1,x_2). </mrow>
			</mdn>
			For such a system we can again use a direction field to visualize the global behavior. At a point in the <m>(x_1,x_2)</m> plane, the vector <m>[f_1(x_1,x_2),f_2(x_1,x_2)]</m> is tangent to the solution curve passing through that point. 
		</p>
		<example xml:id="nl-ex-direction-field-system">
			<title>Direction field for a system of two equations</title>
			<p> 
				Here is a direction field for the linear ODE system
				<md>
					<mrow>\dd{x}{t} \amp = -y</mrow>
					<mrow>\dd{y}{t} \amp = x</mrow>
				</md>. 
			</p>
			<sidebyside>
				<listing xml:id="nl_dirfield_1">
					<program language="matlab">
						<input>
							F = @(x,y) -y;   G = @(x,y) x;
							
							slopefield(F,G,[-2 2],[-2 2])
						</input>
					</program>
				</listing>
				<image source="figures/nl_dirfield_1.svg"/>
			</sidebyside>
			<p> 
				Here is a slope field in the first quadrant for the nonlinear system
				<md>
					<mrow>\dd{x}{t} \amp = 3x - \frac{1}{2}xy</mrow>
					<mrow>\dd{y}{t} \amp = \frac{1}{4}xy - y</mrow>
				</md>. 
			</p>
			<sidebyside>
				<listing xml:id="nl_dirfield_2">
					<program language="matlab">
						<input>
							F = @(x,y) 3.*x-x.*y/2;
							G = @(x,y) -y + x.*y/4;
							
							slopefield(F,G,[0 10],[0 12])
						</input>
					</program>
				</listing>
				<image source="figures/nl_dirfield_2.svg"/>
			</sidebyside>
		</example>	
	</introduction>
	
<subsection xml:id="nl-sec-linearization">
	<title>Linearization</title>
	<p>
		An equilibrium solution of the system <xref ref="nl-eq-system1"/>-<xref ref="nl-eq-system2"/> is a pair of values <m>(x_1^*,x_2^*)</m> such that <m>f_1(x_1^*,x_2^*)=f_2(x_1^*,x_2^*)=0</m>. We can understand the dynamics near an equilibrium point by approximating the nonlinear system with a linear one. Specifically, we use the multivariate linearizations 
		<md>
			<mrow>f_1(x_1,x_2) \amp \approx f_1(x_1^*,x_2^*) + \pp{f_1}{x_1} (x_1-x_1^*) + \pp{f_1}{x_2} (x_2-x_2^*)</mrow>
			<mrow>f_2(x_1,x_2) \amp \approx f_2(x_1^*,x_2^*) + \pp{f_2}{x_1} (x_1-x_1^*) + \pp{f_2}{x_2} (x_2-x_2^*)</mrow>
		</md>, 
		where it is understood for brevity that the partial derivatives are all evaluated at <m>(x_1^*,x_2^*)</m>. The first term in each expansion is zero due to the equilibrium assumption. Now define <m>u_1(t)=x_1(t)-x_1^*</m>, <m>u_2(t)=x_2(t)-x_2^*</m> to arrive at 
		<md>
			<mrow>\dd{u_1}{t} \amp \approx \pp{f_1}{x_1} u_1 + \pp{f_1}{x_2} u_2, </mrow>
			<mrow>\dd{u_2}{t} \amp \approx \pp{f_2}{x_1} u_1 + \pp{f_2}{x_2} u_2. </mrow>
		</md>
		This motivates the following definition.
	</p>
	<definition xml:id="nl-def-jacobian">
		<title>Jacobian matrix</title>
		<statement><p>
			The <idx>Jacobian matrix</idx><term>Jacobian matrix</term> of the system <xref ref="nl-eq-system1"/>-<xref ref="nl-eq-system2"/> is 
			<men xml:id="nl-eq-jacobian">
				\bJ(x_1,x_2) = \twomat{\pp{f_1}{x_1}}{\pp{f_1}{x_2}}{\pp{f_2}{x_1}}{\pp{f_2}{x_2}}
			</men>. 
		</p></statement>
	</definition>
	<aside>
		<p>
			Just as a derivative of <m>f(x)</m> is a function of <m>x</m>, a Jacobian matrix is a function of the variables of the system. 
		</p>
	</aside>
	<p>
		Let's summarize. In the neighborhood of a fixed point <m>(x_1^*,x_2^*)</m>, we can define the <q>deviation from equilibrium</q> as the variables <m>u_i(t)=x_i(t)-x_i^*</m> for <m>i=1,2</m>. These variables approximately satisfy <m>\bu'=\bJ(x_1^*,x_2^*)\bu</m>, which is a linear, constant-coefficient system in two dimensions. This is a huge revelation: <alert>near a steady state, dynamics are mostly linear</alert>. 
	</p>
	<p>
		We are now right back into the situation of <xref ref="fs-phaseplane"/>. In particular: 
	</p>
	<fact>
		<p>
			The stability of a steady state is (usually) determined by the eigenvalues of the Jacobian matrix at the steady state. 
		</p>
	</fact>
	<example>
		<title>Linearization of the pendulum</title>
		<p>
			Let's examine the steady states of a pendulum with damping, 
		<me>
			\ddd{\theta}{t} + \gamma \theta' + \frac{g}{L} \sin(\theta) = 0
		</me>,
		with <m>\gamma \gt 0</m>. It transforms into the first-order system
		<md>
			<mrow>\dd{x_1}{t} \amp = x_2 </mrow>
			<mrow>\dd{x_2}{t} \amp = -\frac{g}{L}\sin(x_1) - \gamma x_2</mrow>
		</md>. 
		These define <m>f_1</m> and <m>f_2</m>. From here we note all the first partial derivatives: 
		<md>
			<mrow>\pp{f_1}{x_1} = 0 \amp \qquad \pp{f_1}{x_2} = 1</mrow>
			<mrow>\pp{f_2}{x_1} = - \frac{g}{L}\cos(x_1) \amp \qquad \pp{f_2}{x_2} = -\gamma</mrow>
		</md>.
		</p>
		<p>    
		The first steady state we consider is at the origin. Here the Jacobian matrix is 
		<me>
			\begin{bmatrix} 
			0 \amp 1 \\ -g/L \amp -\gamma
			\end{bmatrix} 
		</me>. 
		The eigenvalues are 
		<me>
			\frac{-\gamma \pm \sqrt{\gamma^2 - 4(g/L)}}{2}. 
		</me>
		If the radical is imaginary, then the real part is <m>-\gamma/2 \lt 0</m>. If it is real, then it is in the interval <m>(0,\gamma)</m>, so the eigenvalues are real and negative. Hence the origin is stable, as either a spiral point or a node. That comports with our expectations of a pendulum hanging straight down!
		</p>
		<p>
			The other physically distinct equilibrium is at <m>(\pi,0)</m>, i.e., the inverted position at rest. Now the Jacobian is
		<me>
			\begin{bmatrix} 
			0 \amp 1 \\ g/L \amp -\gamma
			\end{bmatrix}
		</me>, 
		with eigenvalues 
		<me>
			\frac{-\gamma \pm \sqrt{\gamma^2 + 4(g/L)}}{2}. 
		</me>
		Now the radical is always real and greater than <m>\gamma</m>, so the eigenvalues are real and of opposite signs. Hence the inverted position is an unstable saddle point. 
		</p>
	</example>
	<example>
		<title>van del Pol equation</title>
		<p>
			The <idx>van der Pol equation</idx><term>van der Pol equation</term> is a nonlinear oscillator in the form <m>y''+\mu(y^2-1)y'+y=0</m> for parameter <m>\mu \gt 0</m>. It is equivalent to the system 
			<md>
				<mrow> x_1' \amp = x_2  </mrow>
				<mrow> x_2' \amp = -x_1 - \mu(x_1^2-1)x_2,  </mrow>
			</md>
			which has the sole equilibrium point <m>(0,0)</m>. The Jacobian matrix is 
			<me>
				\twomat{0}{1}{-1-2\mu x_1 x_2}{-\mu(x_1^2-1)}, 
			</me>
			which at the origin is simply <m>\twomat{0}{1}{-1}{\mu}</m>. This has eigenvalues
			<me>
				\frac{1}{2} \left( {\mu} \pm \sqrt{\mu^2-4} \right). 
			</me>
			If <m>0\lt \mu \lt 2</m>, the origin is an unstable spiral point. If <m>\mu > 2</m>, the origin is an unstable node, as you can never achieve a negative eigenvalue. 
		</p>
	</example>
	<p>
		The caveat on using eigenvalues for stability is when they both have zero real part, which is a neutrally stable center in the linear sense. In such cases the details of the nonlinear terms of the system can swing the stability either way. 
	</p>
	<example>
		<title>Linearization of predator-prey</title>
		<p>
			The system 
			<md>
			<mrow>\frac{dx}{dt} \amp= 3x-\frac{xy}{2}</mrow>
			<mrow>\frac{dy}{dt} \amp= -y+\frac{xy}{4}</mrow>
			</md>
			is called a <idx>predator-prey model</idx><term>predatorâ€“prey</term> equation. If species <m>y</m> is set to zero, species <m>x</m> would grow exponentially on its own (the prey). Similarly, species <m>y</m> would die off on its own (predator). We assume that encounters between the species are jointly proportional to the population of each, and they subtract from the prey and add to the predators. 
		</p>
		<p>
			We find fixed points when <m>3x-(x y/2)=(x y/4)-y=0</m>, which has two solutions, <m>(0,0)</m> and <m>(4,6)</m>. The Jacobian matrix of the system is 
			<me>
				\mathbf{A} =  \begin{bmatrix} 3-y/2 \amp -x/2 \\ y/4 \amp -1+x/4 \end{bmatrix}
			</me>. 
			At the origin, the Jacobian becomes
			<me>
				 \begin{bmatrix} 3 \amp 0 \\ 0 \amp -1 \end{bmatrix}
			</me>. 
			The eigenvalues of a diagonal matrix are the diagonal entries. Hence the origin is a saddle point. 
		</p>
		<p>
			At the other steady state we have the Jacobian
				<me>
				\twomat{0}{-2}{3/2}{0}
			</me>. 
			The characteristic polynomial is <m>\lambda^2 - 0\lambda + 3</m>, so the eigenvalues are <m>\pm i\sqrt{3}</m>. Hence this fixed point is a center. Close to the point, the orbits are impossible to tell apart from those of a linear center:       
		</p>
		<sidebyside>
			<image source="figures/linearized_center1.svg"/>
		</sidebyside>        
		<p>
			However, as we zoom out, the nonlinearity of the system makes its influence felt:
		</p>
			<sidebyside>
			<image source="figures/linearized_center2.svg"/>
		</sidebyside>
		<p>
			In this particular case the solution curves continue to close up, suggesting that all these solutions are periodic. 
		</p>
	</example>
</subsection>
</section>
	
</chapter>