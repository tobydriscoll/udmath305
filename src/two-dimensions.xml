<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="two-dimensional-systems" xmlns:xi="http://www.w3.org/2001/XInclude">
	
<title>2D systems</title>
 
<section xml:id="twod-slope-fields">
    <title>Slope fields</title>
    <p><em>From section 3.1.</em></p>
    <p>
        In nonlinear problems of the form <m>y'=f(y)</m>, we used the idea of a phase-line diagram to get some insight to the behavior of the solution, in particular with regards to the stability of fixed points where <m>f(y)=0</m>. For a more general (nonautonomous) equation of the form <m>y'=f(t,y)</m>, we can use a two-dimensional form of this picture called a <term>slope field</term> or <term>direction field</term>. 
    </p>
    <p>
        The idea is to choose a section of the <m>(t,y)</m> plane and evaluate <m>f(t,y)</m> at a grid of points there. At each such point we thus have the value of <m>y'</m>, i.e., the slope of the solution. The value is indicated using an arrow or hash mark whose slope shows the direction and whose length shows the magnitude of <m>y'</m>. 
    </p>

    <example xml:id="twod-ex-slope-fields">

        <title>Slope fields for single equations</title>
        <p> 
            Here are slope fields drawn by MATLAB (see main site for code). 
            <me>\dd{y}{t} = y</me>
        </p>
        <sidebyside>
	        <program language="matlab" permid="twoD_slope1">
            <input>
            slopefield(@(t,y) y,[0 3],[-1 1])
	        </input>
	        </program>
	        <image source="matlab/twoD_slope1.svg"/>
         </sidebyside>
        <p>
            You clearly see the instability of <m>y=0</m>.
        </p>
        <p>  
            <me>\dd{y}{t} = -y</me>
        </p>
        <sidebyside>
	        <program language="matlab" permid="twoD_slope2">
            <input>
            slopefield(@(t,y) -y,[0 3],[-1 1])
	        </input>
	        </program>
	        <image source="matlab/twoD_slope2.svg"/>
         </sidebyside>
         <p>
            Now <m>y=0</m> is stable.
         </p>
        <p> (Logistic)
            <me>\dd{y}{t} = 4y-y^2</me>
        </p>
        <sidebyside>
	        <program language="matlab" permid="twoD_slope3">
            <input>
            slopefield(@(t,y) 4*y-y.^2,[0 4],[0 5])
	        </input>
	        </program>
	        <image source="matlab/twoD_slope3.svg"/>
         </sidebyside>
         <p>
            The arrows strongly suggest the S-shaped solutions familiar for the logistic equation.
         </p>
        <p> 
            (Time-varying) 
            <me>\dd{y}{t} = t^2-y</me>
        </p>
        <sidebyside>
	        <program language="matlab" permid="twoD_slope4">
            <input>
            slopefield(@(t,y) t.^2-y,[0 2],[-4 4])
	        </input>
	        </program>
	        <image source="matlab/twoD_slope4.svg"/>
         </sidebyside>
        <p>
            There are no longer fixed points/steady states. 
        </p>
    </example>

    <p>
        A related type of picture emerges from looking at <term>isoclines</term>. An isocline is a curve in the <m>(t,y)</m> plane where <m>f(t,y)</m> is constant. That is, they are level curves of <m>f</m>. Along an isocline, all solution curves have the same slope. The particular case of <m>f(t,y)=0</m> is a <term>nullcline</term>.
    </p>

    <p>
        The isoclines in the autonomous case <m>y'=f(y)</m> are, quite boringly, all horizontal lines. 
    </p>

    <p>
        Let's now make a rather strange-looking shift in how we look at <m>dy/dt=f(t,y)</m>. We introduce a new variable <m>x(t)</m> such that simply <m>x(t)=t</m>. This lets us write the pair of equations
        <md>
        <mrow>\dd{y}{t} \amp = f(x,y)</mrow>
        <mrow>\dd{x}{t} \amp = 1</mrow>
        </md>.
        It now becomes interesting to see this as a special case of an autonomous <em>system</em> of two ODEs for two dependent variables:
        <md>
        <mrow>\dd{x}{t} \amp = F(x,y)</mrow>
        <mrow>\dd{y}{t} \amp = G(x,y)</mrow>
        </md>. 
        Here we can regard solutions <m>(x(t),y(t))</m> as trajectories or curves in the <m>(x,y)</m> plane, with <m>t</m> as a parameter rather than an axis in the plot. At any point on one of these curves, the tangent vector is given by 
        <me>
        \left[ \dd{x}{t},\dd{y}{t} \right] = \bigl[ F(x,y),G(x,y) \bigr]
        </me>. 
        This observation allows us to draw a slope field in the <m>(x,y)</m> plane, even without knowing solutions. A slope field does not give much precise information, but it can give important hints about what to expect.
    </p>


    <example xml:id="twod-ex-slope-field-system">
        <title>Slope fields for a system of two equations</title>
        <p> 
            Here is a slope field for the linear ODE system
            <md>
            <mrow>\dd{x}{t} \amp = -y</mrow>
            <mrow>\dd{y}{t} \amp = x</mrow>
            </md>. 
        </p>
        <sidebyside>
	        <program language="matlab" permid="twoD_slope_2D_1">
            <input>
            F = @(x,y) -y;   G = @(x,y) x;

            slopefieldxy(F,G,[-2 2],[-2 2])
	        </input>
	        </program>
	        <image source="matlab/twoD_slope_2D_1.svg"/>
         </sidebyside>
        <p> 
            Here is a slope field in the first quadrant for the nonlinear system
            <md>
            <mrow>\dd{x}{t} \amp = 3x - \frac{1}{2}xy</mrow>
            <mrow>\dd{y}{t} \amp = \frac{1}{4}xy - y</mrow>
            </md>. 
        </p>
        <sidebyside>
	        <program language="matlab" permid="twoD_slope_2D_2">
            <input>
            F = @(x,y) 3.*x-x.*y/2;
            G = @(x,y) -y + x.*y/4;

            slopefieldxy(F,G,[0 10],[0 12])
	        </input>
	        </program>
	        <image source="matlab/twoD_slope_2D_2.svg"/>
         </sidebyside>
    </example>

    <p>
        There is another way to look at the two-equation system <m>x'=F(x,y)</m>, <m>y'=G(x,y)</m>. If we define a vector-valued function <m>\mathbf{u}(t)</m> by <m>u_1=x,\, u_2=y,</m> and we define the vector field <m>\mathbf{f}(\mathbf{u})</m> with components
        <md>
            <mrow>f_1(\mathbf{u}) \amp = F(u_1,u_2)</mrow>
            <mrow>f_2(\mathbf{u}) \amp = G(u_1,u_2)</mrow>
        </md>,
        then we can express the system as one equation, <m>\mathbf{u}'=\mathbf{f}(\mathbf{u})</m>, whose solution is vector-valued in two dimensions. Writing things in this form serves two major purposes: it allows us to generalize quite easily from two dimensions to any number, and it's the form expected by most software for solving ODE systems numerically.
    </p>
</section>

<section xml:id="twod-fixed-points">
    <title>Linear 2D systems</title>
    <introduction>
        <p><em>From section 3.2.</em></p>
    </introduction>
    <subsection>
        <title>State space and phase portraits</title>
        <p>
            For second-order ODEs, we saw that fully specifying a unique solution required giving initial values for <m>y</m> and <m>y'</m>. We say that <m>(y(t),y'(t))</m> together constitute the <term>state</term> of the system at a certain time. Knowing only part of the state isn't specific enough. The two-dimensional space of all possible values of the state is called <term>state space</term>, or in the 2D case only, the <term>phase plane</term>. A plot of many solutions of an ODE in the phase plane is called a <term>phase portrait</term> of the system. 
        </p>
        <example xml:id="ex-phase-node">
            <title>Phase portrait of a node</title>
            <p>
                Here we give a phase portrait for the equation <m>y''+8y'+4y=0</m>. 
            </p>
            <sidebyside>
	        <program language="matlab" permid="twoD_phase_node">
            <input>
A = 1;  B = 8;  C = 4;
s = roots([A B C]);

plot(0,0,'r.','markersize',18)
    
% Plot trajectories
hold on
colr = get(gca,'colororder');
t = linspace(0,10,300);
for theta = 2*pi*(0:23)/24
    c = [1 1;s(1) s(2)] \ [ cos(theta); sin(theta) ];
    y = c(1)*exp(s(1)*t) + c(2)*exp(s(2)*t);
    dydt = s(1)*c(1)*exp(s(1)*t) + s(2)*c(2)*exp(s(2)*t);
    plot(y,dydt,'linew',1.5,'color',colr(1,:))
end

axis([-1.1 1.1 -1.1 1.1]), axis square
title(['node'])
xlabel('y')
ylabel('y''')
	        </input>
	        </program>
	        <image source="matlab/twoD_phase_node.svg"/>
            </sidebyside>
            <p>
                The characteristic roots are negative and real, so all solutions are of the form <m>y=c_1 e^{s_1t} + c_2 e^{s_2 t}</m>, where <m>s_2\lt s_1 \lt 0</m>. As time advances, <m>e^{s_2 t}</m> decays more rapidly than the other exponential, so <m>y\approx c_1 e^{s_1 t}</m> and <m>y'\approx c_1 s_1 e^{s_1 t}</m>. That is, solutions in the phase plane asymptotically approach the origin parallel to the vector <m>(1,s_1)</m>. In this situation we say that the origin is a <term>node</term> of the ODE. 
            </p>
        </example>

        <p>
            More specifically in <xref ref="ex-phase-node"/> we call the origin a <term>nodal sink</term>, because all trajectories are sucked into the origin. If the characteristic equation had two positive roots the picture would be the same, but all traversal directions reversed, and the point would be a <term>nodal source</term>.
        </p>

        <example>
            <title>Phase portrait of a saddle</title>
            <p>
                Here we give a phase portrait for the equation <m>y''+6y'-3y=0</m>. 
            </p>
            <sidebyside>
	        <program language="matlab" permid="twoD_phase_saddle">
            <input>
A = 1;  B = 6;  C = -3;
s = sort(roots([A B C]),'descend');

plot(0,0,'r.','markersize',18)
    
% Plot trajectories
hold on
colr = get(gca,'colororder');
t = linspace(0,15,300)';
for theta = 2*pi*(0:23)/24
    c = [1 1;s(1) s(2)] \ [ cos(theta); sin(theta) ];
    y = c(1)*exp(s(1)*t) + c(2)*exp(s(2)*t);
    dydt = s(1)*c(1)*exp(s(1)*t) + s(2)*c(2)*exp(s(2)*t);
    plot(y,dydt,'linew',1.5,'color',colr(1,:))
end
y = 2*exp(s(2)*t); dydt = 2*s(2)*exp(s(2)*t);
plot([y -y],[dydt -dydt],'k','linew',1.5)
y = 2*exp(-s(1)*t); dydt = 2*s(1)*exp(-s(1)*t);
plot([y -y],[dydt -dydt],'k','linew',1.5)

axis([-1.5 1.5 -1.5 1.5]), axis square
title('saddle')
xlabel('y')
ylabel('y''')
	        </input>
	        </program>
	        <image source="matlab/twoD_phase_saddle.svg"/>
            </sidebyside>
            <p>
                In this case all solutions are of the form <m>y=c_1 e^{s_1t} + c_2 e^{s_2 t}</m> where <m>s_2\lt 0 \lt s_1</m>. As time advances, <m>e^{s_2 t}</m> decays to zero while the other exponential grows, so again <m>y\approx c_1 e^{s_1 t}</m> and <m>y'\approx c_1 s_1 e^{s_1 t}</m>. That is, solutions in the phase plane asymptotically move away from the origin parallel to the vector <m>(1,s_1)</m>. The only exception is if <m>c_1=0</m>, in which case solutions go straight toward the origin forever. (Solutions with <m>c_2=0</m> go toward the origin in "backward time.") In this situation we say that the origin is a <term>saddle</term>. 
            </p>
        </example>
   
        <p>
            A saddle has both sink and source behaviors simultaneously. But the source nature wins out unless you approach the origin <em>just</em> so. 
        </p>

        <example xml:id="ex-phase-center">
            <title>Phase portrait of a center</title>
            <p>
                Here is a phase portrait for the equation <m>y''+2y=0</m>. 
            </p>
            <sidebyside>
	        <program language="matlab" permid="twoD_phase_center">
            <input>
A = 1;  B = 0;  C = 2;
s = roots([A B C]);

plot(0,0,'r.','markersize',18)
    
% Plot trajectories
hold on
colr = get(gca,'colororder');
t = linspace(0,15,1000)';
for R = .2:.2:1
    y = R*real(exp(s(1)*t));
    dydt = R*real(s(1)*exp(s(1)*t));
    plot(y,dydt,'linew',1.5,'color',colr(1,:)), hold on
end
axis([-1.5 1.5 -1.5 1.5]), axis square
title('center')
xlabel('y')
ylabel('y''')
	        </input>
	        </program>
	        <image source="matlab/twoD_phase_center.svg"/>
            </sidebyside>
            <p>
                The characteristic roots are imaginary and the solutions are, in shifted cosine form, <m>y=R\cos(\omega_n t-\phi)</m>. Solution curves in the phase plane lie on the ellipses <m>y^2+(y'/\omega_n)^2=R^2</m>, going around and around the origin, which we call a  <term>center</term> of the ODE. If <m>\omega_n=1</m>, the ellipses are circles. 
            </p>
        </example>

        <example xml:id="ex-phase-spiral">
            <title>Phase portrait of a spiral</title>
            <p>
                Here is a phase portrait for the equation <m>y''+0.6y'+3y=0</m>. 
            </p>
            <sidebyside>
	        <program language="matlab" permid="twoD_phase_spiral">
            <input>
A = 1;  B = .6;  C = 3;
s = roots([A B C]);

plot(0,0,'r.','markersize',18)
    
% Plot trajectories
hold on
colr = get(gca,'colororder');
t = linspace(0,12,1000)';
for phi = 2*pi*(0:5)/6
    y = real(exp(s(1)*t-1i*phi));
    dydt = real(s(1)*exp(s(1)*t-1i*phi));
    plot(y,dydt,'linew',1.5,'color',colr(1,:)), hold on
end
axis([-1.5 1.5 -1.5 1.5]), axis square
title('spiral')
xlabel('y')
ylabel('y''')
	        </input>
	        </program>
	        <image source="matlab/twoD_phase_spiral.svg"/>
            </sidebyside>
            <p>
                The characteristic roots are complex conjugates with negative real part (underdamped). Solutions decay exponentially while they oscillate, and we say that the origin is a <term>spiral point</term> of the ODE. 
            </p>
        </example>

        <p>
            As with nodes, spiral points can be either sinks or sources, which is just a matter of reversing the direction of travel along solution curves. 
        </p>

    </subsection>

    <subsection>
        <title>Second-order equations as first-order systems</title>
        <p>
            Above we drew some phase portraits for instances of the second-order problem <m>Ay''+By'+Cy=0</m>. Here is another way of looking at them. Let's define a time-varying vector with components <m>u_1=y</m> and <m>u_2=y'</m>.  We can call <m>\mathbf{u}(t)</m> the <term>state vector</term> of the ODE. From the definitions we find
            <md>
                <mrow>\dd{u_1}{t} \amp = u_2 </mrow>
                <mrow>\dd{u_2}{t} \amp = \frac{1}{A}(-Cu_1 -Bu_2) </mrow>
            </md>,
            which is in the form <m>\mathbf{u}'=\mathbf{f}(\mathbf{u})</m>. All the phase portraits above are unchanged if we simply label the axes as <m>u_1,u_2</m>. 
        </p>
        <p>
            We can generalize the systems under study a bit to 
             <md>
                <mrow>\dd{u_1}{t} \amp = a_{11} u_1 + a_{12} u_2 </mrow>
                <mrow>\dd{u_2}{t} \amp = a_{21} u_1 + a_{22} u_2 </mrow>
            </md>,
            where the <m>a_{ij}</m> are all constants. This is a first-order, two-dimensional, linear, constant-coefficient, homogeneous system that we abbreviate as 
            <me>
                \dd{\mathbf{u}}{t} = \mathbf{A} \mathbf{u}
            </me>,
            where <m>\mathbf{A}</m> is the <term>matrix</term>
            <me>
                \mathbf{A} = \begin{bmatrix} a_{11} \amp a_{12} \\ a_{21} \amp a_{22} \end{bmatrix}
            </me>.
            As the text says, the matrices we get from problems <m>Ay''+By'+Cy=0</m> are called <term>companion matrices</term>.  
       </p>
       <p>
            It's fair to ask what kinds of phase portraits we can get for this type of problem. The answer is: same as the above. The extra generality in the first row of the matrix can change the details, but there are no new major kinds of behavior beyond node, saddle, and spiral. We are now going to shift away from talking about the second-order problem to the more general <m>\mathbf{u}' = \mathbf{A} \mathbf{u}</m>. 
       </p>
    </subsection>
    
    <subsection>
        <title>Stability</title>
        <p>
            For first-order autonomous problems <m>y'=f(y)</m>, we paid special attention to the steady states and their stability. What is the analog for 
            <md>
                <mrow>\dd{u_1}{t} \amp = a_{11} u_1 + a_{12} u_2 </mrow>
                <mrow>\dd{u_2}{t} \amp = a_{21} u_1 + a_{22} u_2 </mrow>
            </md>,
            or more simply, <m>\mathbf{u}' = \mathbf{A} \mathbf{u}</m>? 
        </p>
        <p>
            Right away it's clear that we have a steady state at <m>\bu=\mathbf{0}</m>. We'll have others, if there are nonzero solutions to the system <m>\bA\bu=\mathbf{0}</m>. That's a question we'll take up much later, so we'll ignore these for now. 
        </p>
        <p>
            The phase portraits we have done are all in the vicinity of the fixed point at the origin, and they tell the story of stability. Sinks (node or spiral) are stable points, while sources (node or spiral) and saddles are unstable. The case of a center is on the cusp, what we might call "neutrally stable" or weakly stable. 
        </p>
        <p>
            So the phase portraits are a graphical tool for stability. What about analytical tools? The key here turns out to be the <term>eigenvalues</term> of the matrix <m>\bA</m>.  We're not ready to discuss those in generality yet, but the 2-by-2 case is simple to describe (and hauntingly familiar). The eigenvalues are the two roots of the <term>characteristic polynomial</term>
            <me>
                p(\lambda) = \lambda^2 - T\lambda + D
            </me>,
            where <m>T=a_{11}+a_{22}</m> is the <term>trace</term> and <m>D=a_{11}a_{22}-a_{12}a_{21}</m> is the <term>determinant</term> of the matrix. Each eigenvalue <m>\lambda_k</m> implies a solution with time dependence <m>\exp(\lambda_k t)</m> (unless the eigenvalues coincide, in which case <m>t\exp(\lambda_k t)</m> can emerge). Hence stability is determined by the real parts of the eigenvalues:
            <ol>
                <li>If <m>\Re\lambda_k \gt 0</m> for either value of <m>k</m>, the origin is unstable.</li>
                <li>If <m>\Re\lambda_k \leq 0</m> for both <m>k</m>, and <m>\lambda_1\neq \lambda_2</m>, the origin is stable.</li>
                <li>If <m>\lambda_1 = \lambda_2</m>, the origin is unstable.</li>
            </ol>
            Furthermore, in the first two cases, point is a node if the imaginary parts of the eigenvalues are zero, and a spiral or center if they are nonzero. 
        </p>
        <p>
            We don't even have to compute the eigenvalues to figure out the stability. If you add the roots of the quadratic formula, you can confirm that 
            <me>
                \lambda_1 + \lambda_2 = T
            </me>. 
            If you multiply them, you find
             <me>
                \lambda_1 \lambda_2 = D
            </me>. 
            Suppose the eigenvalues are real. The only way to keep them both negative is if <m>T\lt 0</m> and <m>D \gt 0</m>; if one is zero and the other negative, then <m>T \lt 0</m>, <m>D=0</m>. Now suppose the eigenvalues are <m>\alpha \pm i\beta</m>  with nonzero <m>\beta</m>. We find that <m>D\gt 0</m>, and that <m>\alpha \leq 0</m> if and only if <m>T \leq 0</m>.   
        </p>
        <table>
        <caption>Origin character based on trace and determinant</caption>
        <tabular>
            <row>
            <cell></cell>
            <cell halign="center" bottom="medium"> <m>T\lt 0​</m></cell>
            <cell halign="center" bottom="medium"><m>T=0​</m></cell>
            <cell halign="center" bottom="medium"><m>T\gt 0</m></cell>
            </row>
            <row>
            <cell right="medium"> <m>D\lt 0</m></cell>
            <cell halign="center" right="medium" bottom="medium">unstable, saddle</cell>
            <cell halign="center" right="medium" bottom="medium">unstable, saddle</cell>
            <cell halign="center" right="medium" bottom="medium">unstable, saddle</cell>
            </row>
            <row>
            <cell right="medium">   <m>D=0</m></cell>
            <cell halign="center" right="medium" bottom="medium">stable</cell>
            <cell halign="center" right="medium" bottom="medium">?</cell>
            <cell halign="center" right="medium" bottom="medium">unstable</cell>
            </row>
            <row>
            <cell right="medium"><m>D\gt 0</m></cell>
            <cell halign="center" right="medium" bottom="medium">stable, sink</cell>
            <cell halign="center" right="medium" bottom="medium">stable, center</cell>
            <cell halign="center" right="medium" bottom="medium">unstable, source</cell>
            </row>
        </tabular>
        </table>
    </subsection>
</section>

<section xml:id="twod-linearization">
    <title>Linearization</title>
    <p><em>From section 3.3, but you can stop at page 174.</em></p>
    <p>
        A pendulum with length <m>L</m> and angle of deflection <m>\theta(t)</m> from the vertical is governed by the nonlinear second-order equation
        <me>
            \ddd{\theta}{t} + \frac{g}{L} \sin(\theta) = 0
        </me>,
        where <m>g</m> is gravitational acceleration. It's standard to argue that as long as <m>|\theta|</m> remains small, a good approximation is the linear problem 
         <me>
            \ddd{\theta}{t} + \frac{g}{L} \theta = 0
        </me>,
        because <m>\sin \theta \approx \theta</m>.  We want to get more systematic with this process. 
   </p>
   <p>
       First note that we can recast the nonlinear problem as a first-order system in two variables. Define <m>x=\theta</m> and <m>y=\theta'</m>. Then
       <md>
           <mrow>\dd{x}{t} \amp = y </mrow>
           <mrow>\dd{y}{t} \amp = -\frac{g}{L}\sin(x)</mrow>
       </md>. 
       This trick works for any nonlinear second-order equation <m>\theta''=g(t,\theta,\theta')</m>. Thus we can focus on problems in the general form 
        <md>
           <mrow>\dd{x}{t} \amp = F(x,y) </mrow>
           <mrow>\dd{y}{t} \amp = G(x,y)</mrow>
       </md>, 
       or <m>\bu' = \bff(\bu)</m> for 2-vector <m>\bu(t)</m>. Note that (as we saw before), the vector <m>\bu</m> represents the state of the system.
   </p>
   <p>
       As we did with single scalar equations, we will pay close attention to <term>steady states</term> or <term>fixed points</term> of these systems. Here this means constants <m>(x_p,y_p)</m> such that <m>F(x_p,y_p)=G(x_p,y_p)=0</m>. For the nonlinear pendulum, both <m>(0,0)</m> and <m>(\pi,0)</m> are steady states. 
   </p>
   <p>
       We are interested in the stability of fixed points, that is, the dynamics close to them. We will use linear approximations of the functions <m>F</m> and <m>G</m> near a fixed point:
       <md>
           <mrow>F(x,y) \amp \approx F(x_p,y_p) + \pp{F}{x} (x-x_p) + \pp{F}{y} (y-y_p)</mrow>
           <mrow>G(x,y) \amp \approx G(x_p,y_p) + \pp{G}{x} (x-x_p) + \pp{G}{y} (y-y_p)</mrow>
       </md>, 
       where it is understood that the partial derivatives are all evaluated at <m>(x_p,y_p)</m>. Given that <m>(x_p,y_p)</m> is a fixed point, two terms above are zero. Finally, define <m>u_1(t)=x(t)-x_p</m>, <m>u_2(t)=y(t)-y_p</m> to arrive at 
        <md>
           <mrow>\dd{u_1}{t} \amp \approx \pp{F}{x} u_1 + \pp{F}{y} u_2 = a_{11} u_1 + a_{12}u_2</mrow>
           <mrow>\dd{u_2}{t} \amp \approx \pp{G}{x} u_1 + \pp{G}{y} u_2 = a_{21} u_1 + a_{22} u_2</mrow>
       </md>. 
       We are back at the linear, constant-coefficient system <m>\bu'=\bA \bu</m>!  The matrix <m>\bA</m> is called the <term>Jacobian matrix</term> at the fixed point. So it's the eigenvalues of the Jacobian matrix that determine the stability of a steady state. 
   </p>
   <example>
       <title>Linearization of the pendulum</title>
       <p>
           Let's examine the steady states of a pendulum with damping, 
        <me>
            \ddd{\theta}{t} + \gamma \theta' + \frac{g}{L} \sin(\theta) = 0
        </me>,
        with <m>\gamma \gt 0</m>. It transforms into the first-order system
        <md>
           <mrow>\dd{x}{t} \amp = y </mrow>
           <mrow>\dd{y}{t} \amp = -\frac{g}{L}\sin(x) - \gamma y</mrow>
       </md>. 
       These define <m>F(x,y)</m> and <m>G(x,y)</m>. From here we note all the first partial derivatives: 
        <md>
            <mrow>\pp{F}{x} = 0 \amp \qquad \pp{F}{y} = 1</mrow>
            <mrow>\pp{G}{x} = - \frac{g}{L}\cos(x) \amp \qquad \pp{G}{y} = -\gamma</mrow>
        </md>.
        </p>
        <p>    
       The first steady state we consider is at the origin. Here the Jacobian matrix is 
       <me>
           \begin{bmatrix} 
           0 \amp 1 \\ -g/L \amp -\gamma
           \end{bmatrix}
       </me>. 
       We get <m>T=-\gamma \lt 0</m> and <m>D=g/L \gt 0</m>, which is a stable sink. That comports with our experience with a pendulum hanging straight down!
        </p>
        <p>
            The other steady state is at <m>(\pi,0)</m>. Now the Jacobian is
        <me>
           \begin{bmatrix} 
           0 \amp 1 \\ g/L \amp -\gamma
           \end{bmatrix}
       </me>, 
        with <m>T=-\gamma</m> and <m>D=-g/L</m>. This implies a saddle point, so the "inverted pendulum" is indeed unstable. 
        </p>
   </example>

   <p>
       This is just the tip of a huge iceberg: <em>near a steady state, dynamics are mostly linear</em>. It applies in any number of dimensions through a natural extension of the definition of the Jacobian matrix. Rather than pursuing this line of thought now deeper into different nonlinear examples, we will instead get serious about understanding eigenvalues, which means first getting serious about understanding matrices.
   </p>
</section>
</chapter>



